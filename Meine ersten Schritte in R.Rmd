---
title: "Etwas R am Abend"
subtitle: "Eine erweiterte Mitschrift"
author: "Norman Markgraf"
date: "5. Juni 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mosaic)
```

## Vorbereitung

Wir starten damit, als erstes das Paket *mosaic* zu laden und den Datensatz *Houses* direkt aus dem Internet in den Speicher zu laden:

```{r}
# Paket laden
library(mosaic)

# URL
daten_url <- "http://statistix.org/Data/SaratogaHouses.csv"

# Daten einlesen
Houses <- read.csv2(daten_url)
```

Einen kleinen Überblick über den Datensatz liefert der Befehl `inspect()`:

```{r}
inspect(Houses)
```

Wer direkt in den Datensatz gucken möchte, der kann sich den Anfang und das Ende einmal ansehen:
```{r}
# Die ersten Beobachtungen (Zeilen):
head(Houses)
```

```{r}
# Die letzten Beobachtungen (Zeilen):
tail(Houses)
```



## Schlaglichter kleiner explorativer Datenanalysen (EDA)

Um zu sehen wir sehr der Ansatz 

```{r, eval=FALSE}
analysiere( mein.y ~ mein.x, data = meine.Daten)
```

von *mosaic* trägt hier ein paar kleine Ansätze für explorative Datenanalysen (EDA) und ein paar Tests.

### Eine kurze EDA einer kategorialer Variabel (Klimaanlage)

```{r}
# Die Verteilung als Säulendiagramm:
gf_bar( ~ Klimaanlage, data=Houses)
```

```{r}
# Tabelle:
tally( ~ Klimaanlage, data=Houses)
```

```{r}
# Anteilswerte:
prop( ~ Klimaanlage, success="Ja", data=Houses)
```


### Eine kurze EDA einer numerischen Variabel (Preis)

```{r}
# Die Verteilung als Histogramm
gf_histogram( ~ Preis, data=Houses)
```

```{r}
# Übliche Kennzahlen zum Preis
favstats( ~ Preis, data=Houses)
```

```{r}
# Mittelwert / mittlerer Preis der Häuser
mean( ~ Preis, data=Houses)
```


### Eine kurze EDA zweier kategorialer Variabeln (Kamin und Klimaanlage)

```{r}
# Grafische Darstellung als Mosaikplot
mosaicplot(Kamin ~ Klimaanlage, data=Houses)
```

```{r}
# Kreuztabelle der Beziehung
tally(Kamin ~ Klimaanlage, data=Houses)
```

```{r}
# Chi-Quadrat Test
xchisq.test(Kamin ~ Klimaanlage, data=Houses)
```


###  Eine kurze EDA zweier numerischer Variabeln (Preis und Wohnflaeche)

```{r}
# Streudiagramm
gf_point(Preis ~ Wohnflaeche, data=Houses)
```

```{r}
# Korrelationskoeffizent der Stichprobe
cor(Preis ~ Wohnflaeche, data=Houses)
```

```{r}
# Korrelationstest
cor.test(Preis ~ Wohnflaeche, data=Houses)
```



### Hat eine Klimaanlage einen Einfluss darauf ob es einen Kamin gibt?

```{r}
# Säulendiagramme als Visualisierung der Situation
gf_bar( ~ Kamin | Klimaanlage, data= Houses)
```


```{r}
# Anteilswerte
prop( Kamin ~ Klimaanlage,
      success = "Ja",
      data=Houses)
```

```{r}
# Anteilswertstest
prop.test( Kamin ~ Klimaanlage,
           success = "Ja",
           data=Houses)
```

### Hat ein Kamin einen Einfluss auf den Preis des Hauses?

```{r}
# Säulendiagramme als Visualisierung der Situation
gf_histogram( ~ Preis | Kamin, data= Houses)
```


```{r}
# Anteilswerte
mean( Preis ~ Kamin,
      data=Houses)
```

```{r}
# Klassischer t-Test (A/B-Test):
t.test( Preis ~ Kamin,
           data=Houses)
```

## SBI ist nicht (nur) Sally Bollywood Investigation

SBI heißt für uns *S*imulations*b*asierte *I*nferenz. Wir können die beiden Tests von oben (Anteilswertstest und t-Test) auch (und vielleicht sogar besserverständlich) mit den Methoden der SBI lösen:

### Zusammenhang zwischen Kamin und Klimaanlage?

Wir haben oben mit dem folgenden klassischem Anteilswerttests gearbeitet und vielleicht haben Sie die Werte darin auch schon interprätiert.
```{r eval=FALSE}
# Anteilswertstest
prop.test( Kamin ~ Klimaanlage,
           success = "Ja",
           data=Houses)
```

Wir wollen nun mit den Methoden aus der SBI das Problem erneut lösen:

Wegen 
```{r}
prop(Kamin ~ Klimaanlage, success="Ja", data=Houses)
```
sehen wir, dass in der Stichprobe (also unseren Werten im Datensatz *Houses*) ein Unterschied zwischen Häusern mit und ohne Klimaanlage bzgl. des Kamins gibt.

Wir fragen uns nun, ist das ein zufälliges Ergebnis unserer Stichprobe, oder liegt dahinter vielleicht eine Eigenschaft der Population/Grundgesamtheit.

Dazu wählen wir ersteinmal eine Teststatistik, welche diesen Zusammenhang gut beschreibt:

1. Teststatistik wählen

Wir entscheiden uns für die Antweilswertsdifferenz und damit für `diffprop()`:

```{r}
propdiff.stipro <- diffprop(Kamin ~ Klimaanlage, success = "Ja", data=Houses)
propdiff.stipro
```

Wegen 
```{r}
prop(Kamin ~ Klimaanlage, success="Ja", data=Houses)
```
betrachten wir also 

$$
 \hat\pi_{\text{Mit Klimaanlage}} - \hat\pi_{\text{Ohne Klimaanlage}} = `r propdiff.stipro` 
$$

Die Frage ist nun ob wir diesen Effekt auch in der Population erwarten können? 

Wenn die Existenz einer Klimaanlage in keinem Zusammenhang damit steht, ob auch ein Kamin im Haus ist, dann ist die beobachtete Differenz alleine auf den Zufall der Stichprobe zurück zu führen. 

Wie Wahrscheinlich ist es also, wenn wir davon ausgehen, dass es keinen Zusammenhang gibt, dass so eine Antweilswertsdifferenz (oder eine noch extremere) zu beobachten ist?

Dazu wollen wir diese Zusammenhangslosigkeit simulieren:

2. Simulieren einer Verteilung gemäß der Nullhypothese (Nullverteilung)

```{r}
Nullvtlg <- do(10000) * 
  diffprop(Kamin ~ shuffle(Klimaanlage), success = "Ja", data=Houses)
```

Die Verteilung sieht dann wie folgt aus:

```{r}
gf_histogram( ~ diffprop, data=Nullvtlg)
```


Um zu sehen, wie Wahrscheinlich unsere Wert aus der Stichprobe unter dieser Annahme ist, tragen wir ihn noch ein:
```{r}
gf_histogram( ~ diffprop, data=Nullvtlg) %>%
  gf_vline(xintercept = propdiff.stipro)

```


3. Den "P-Wert" bestimmen

Der p-Wert ist auch nur ein Anteilswert. Er bescheibt, unter der Annahme dass die $H_0$ gelte, wie häufig solche Werte, wie der der Stichprobe und noch extremere, bei der Teststatistik vorkommen können. 
Da wir ungerichtet gefragt haben, interessieren uns also die Abweichungen in beide Richtungen, also die absoluten Abweichungen von der $H_0$. 
Diese sagte aus, dass die wahre Antweilswertsdifferenz 0 sei, also bestimmen wir zunächst den Wert für unsere Stichprobe:

```{r}
# Abweichung der stichprobe von dem Wert unter der H_0:
abw.stipro <- abs(propdiff.stipro - 0)
```


Das selbe machen wir nun für jeden Wert unserer Nullverteilung und speichern die Werte in der neuen Spalte/Variable *abw*:

```{r}
Nullvtlg %>%
  mutate(abw = abs(diffprop - 0)) -> Nullvtlg
```

Jetzt können wir den Antweilswert aller der Abweichungen der Nullverteilung bestimmen, die Mindestens so extrem (oder noch extremer) sind wie die der Stichprobe. Das ist der sogenannte **p-Wert**:

```{r}
pvalue <- prop( ~ (abw >= abw.stipro), data=Nullvtlg)
pvalue
```

Der p-Wert liegt mit `r pvalue` unter unserem (üblichen) Signifikanzniveau von $\alpha = 0.05$.

Ausgehen vom formalen Hypothesenpaar
$$
 H_0:  \pi_{\text{Mit Klimaanlage}} - \pi_{\text{Ohne Klimaanlage}} =  0 \text{ vs. }
 H_A:  \pi_{\text{Mit Klimaanlage}} - \pi_{\text{Ohne Klimaanlage}} \neq  0,
$$
welches gleichbedeutend ist mit 
$$
 H_0:  \pi_{\text{Mit Klimaanlage}} = \pi_{\text{Ohne Klimaanlage}} \text{ vs. }
 H_A:  \pi_{\text{Mit Klimaanlage}} \neq \pi_{\text{Ohne Klimaanlage}} ,
$$

haben wir mit dem *p-Wert* nun ein Argument gegen die Nullhypothese ($H_0$) gefunden und lehnen diese daher -- auf Grundlage der Stichprobe und damit vorläufig -- fortan ab.


### Hat ein Kamin einen Einfluss auf den Preis des Hauses?

Auch diese Frage haben wir oben bereits mit Hilfe eines t-Tests beantwortet. Aber auch hier kann SBI helfen.

1. Wahl der Teststatistik

Wärend der t-Test den t-Wert, also die Abweichung des gemessenen Mittelwertes vom hypotetisch angenommenen Mittelwert in Standardfehlern misst und diesen mit der t-Verteilung vergleicht. Gehen wir bei SBI einen direkteren Weg.
Unsere Teststatistik ist die Mittelwertsdifferenz. Wir vergleichen dann die gemessene Mittelwertsdifferenz mit denen, die gewöhnlich unter Annahme der $H_0$ -- also das diese Differenz verschwindet -- vorkommenden Werten von (simulierten) Stichproben (mit dieser Eigenschaft).

Wir berechnen also zuerst die Mittelwertsdifferenz der Stichprobe mit:

```{r}
meandiff.stipro <- diffmean(Preis ~ Kamin, data=Houses)
meandiff.stipro
```

Wegen

```{r}
mean(Preis ~ Kamin, data=Houses)
```

haben wir also
$$
\hat\mu_{\text{Kein Kamin}} - \hat\mu_{\text{Mit Kamin}} = `r meandiff.stipro`
$$

Um zu Testen ob eine solche Differenz auch in der Population zu erwarten ist oder ob dort eigentlich keine Differenz existiert wollen wir diese Zusammenhangslosigkeit simulieren:

2. Simulieren einer Verteilung gemäß der Nullhypothese (Nullverteilung)

```{r}
Nullvtlg <- do(10000) * 
  diffmean(Preis ~ shuffle(Kamin),  data=Houses)
```

Die Verteilung sieht dann wie folgt aus:

```{r}
gf_histogram( ~ diffmean, data=Nullvtlg)
```

Tragen wir nun noch die Mittelwertsdifferenz in das Diagramm ein, so erhalten wir:
```{r}
gf_histogram( ~ diffmean, data=Nullvtlg) %>%
  gf_vline(xintercept = meandiff.stipro)
```

Offenbar ist ein solcher Mittelwertsunterschied nicht üblich, wenn die Nullhypothese gilt. 

3. Den "P-Wert" bestimmen

Analog zu oben berechnen wir zunächst die Abweichung:
```{r}
# Abweichung der stichprobe von dem Wert unter der H_0:
abw.stipro <- abs(meandiff.stipro - 0)
```


Das selbe machen wir nun für jeden Wert unserer Nullverteilung und speichern die Werte in der neuen Spalte/Variable *abw*:

```{r}
Nullvtlg %>%
  mutate(abw = abs(diffmean - 0)) -> Nullvtlg
```

Jetzt können wir den Antweilswert aller der Abweichungen der Nullverteilung bestimmen, die Mindestens so extrem (oder noch extremer) sind wie die der Stichprobe. Das ist der sogenannte **p-Wert**:

```{r}
pvalue <- prop( ~ (abw >= abw.stipro), data=Nullvtlg)
pvalue
```

Der p-Wert liegt mit `r pvalue` unter unserem (üblichen) Signifikanzniveau von $\alpha = 0.05$.

Ausgehen vom formalen Hypothesenpaar
$$
 H_0:  \mu_{\text{Mit Kamin}} - \mu_{\text{Ohne Kamin}} =  0 \text{ vs. }
 H_A:  \mu_{\text{Mit Kamin}} - \mu_{\text{Ohne Kamin}} \neq  0,
$$
welches gleichbedeutend ist mit 
$$
 H_0:  \mu_{\text{Mit Kamin}} = \mu_{\text{Ohne Kamin}} \text{ vs. }
 H_A:  \mu_{\text{Mit Kamin}} = \mu_{\text{Ohne Kamin}},
$$

haben wir mit dem *p-Wert* nun ein Argument gegen die Nullhypothese ($H_0$) gefunden und lehnen diese daher -- auf Grundlage der Stichprobe und damit vorläufig -- fortan ab.

## Epilog

Ich hoffe ich konnte Ihnen den Einsatz von R (und R markdown) ein klein wenig näher bringen. Falls Sie noch Fragen haben, so können Sie mich gerne unter

[nmarkgraf@hotmail.com](mailto:nmarkgraf@hotmail.com?subject=FOM-Workshop-SoSe2019)

anschreiben. Bitte nutzen Sie den Betreff "FOM-Workshop-SoSe2019". - Danke und viel Erfolg weiterhin im Studium!